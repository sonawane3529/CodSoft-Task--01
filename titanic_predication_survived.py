# -*- coding: utf-8 -*-
"""Titanic Predication Survived.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kgKRQhRxiT4v_cXLZrrv2UuNp7a3TfaH

Titanic Survival Prediction
"""

# Importing the libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

"""Data Collecting and Processing.

"""

# Load the dataset and showing first few rows of dataframe.
Titanic = pd.read_csv("Titanic.csv")
Titanic.head()

# No of rows and columns
np.shape(Titanic)

# Getting the information of the data
Titanic.info()

# Returns the description of transpose form
Titanic.describe

# Checking the null values in dataset
Titanic.isnull().sum()

"""Handling the missing values"""

#Handling the missing values
#drop the "Cabin" column from the dataframe
Titanic = Titanic.drop(columns = 'Cabin')
Titanic.head()

#replacing the missing values in "Age" column with the mean value
Titanic['Age'].fillna(Titanic['Age'].mean(), inplace = True)
Titanic['Fare'].fillna(Titanic['Fare'].mean(), inplace = True)
Titanic['Embarked'].fillna(Titanic['Embarked'].mode()[0], inplace=True)

# Encode categorical variables (e.g., Sex, Embarked)
Titanic = pd.get_dummies(Titanic, columns=['Sex', 'Embarked'], drop_first=True)

Titanic.isnull().sum()

#Getting the some statistical measures
Titanic.describe()

#finding the number of people survived and not survived
Titanic['Survived'].value_counts()

"""Data Visualization"""

#mapping values
Titanic.replace({'Sex':{'male':0,'female':1},'Embarked':{'s':0,'c':1,'q':2}},inplace = True)

Titanic.head()

"""Separating Features & Target"""

features = ['Pclass', 'Age', 'Fare', 'Embarked_Q', 'Embarked_S']
X = Titanic[features]
y = Titanic['Survived']

# Define the variable x with some value
x = 10

print(x)
print(y)

"""Splitting the data into training data & Testing data"""

# Split the data into training and testing sets
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(X.shape,X_train.shape, X_test.shape)

"""Training Model"""

# Model and Traning
# Initialize the  RandomForestClassifier
model = RandomForestClassifier()

# Train the model
model.fit(X_train, y_train)

#Doing the prediction of model
X_train_prediction = model.predict(X_train)

# Calculate accuracy on the training data
training_data_accuracy = accuracy_score(y_train, X_train_prediction) * 100
print('Accuracy score of training data:', training_data_accuracy)

"""Evaluating the Model"""

#Checking the accuracy on test data
X_test_prediction = model.predict(X_test)
print(X_test_prediction)

test_data_accuracy = accuracy_score(y_test, X_test_prediction) * 100
print('Accuracy score of test data:', test_data_accuracy)
